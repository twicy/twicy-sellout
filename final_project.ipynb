{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXpAGgv1XpoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a2aa28b-b979-4df0-a049-80495ed01d1f"
      },
      "source": [
        "import pickle\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "import copy\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "from torchvision import datasets, models, transforms\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "print(\"PyTorch Version: \",torch.__version__)\r\n",
        "print(\"Torchvision Version: \",torchvision.__version__)\r\n",
        "# Detect if we have a GPU available\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "if torch.cuda.is_available():\r\n",
        "    print(\"Using the GPU!\")\r\n",
        "else:\r\n",
        "    print(\"WARNING: Could not find GPU! Using CPU only. If you want to enable GPU, please to go Edit > Notebook Settings > Hardware Accelerator and select GPU.\")\r\n",
        "data_dir = \"./data\""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.7.0+cu101\n",
            "Torchvision Version:  0.8.1+cu101\n",
            "Using the GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVLInpQQbVMx"
      },
      "source": [
        "# !pip3 install face_recognition\r\n",
        "!unzip /content/data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vELvzrzTpk3U"
      },
      "source": [
        "def get_dataloaders(input_size, batch_size, shuffle = True):\n",
        "    '''\n",
        "    Build dataloaders with transformations. \n",
        "\n",
        "    Args:\n",
        "        input_size: int, the size of the tranformed images\n",
        "        batch_size: int, minibatch size for dataloading\n",
        "\n",
        "    Returns:\n",
        "        dataloader_dict: dict, dict with \"train\", \"val\", \"test\" keys, each is mapped to a pytorch dataloader.\n",
        "\n",
        "    '''\n",
        "\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    #++++++++++++++++++++++++++++++++++++++++++++++#\n",
        "    #++++++++++++++++++++++++++++++++++++++++++++++#\n",
        "    # ============== YOUR CODE HERE ============== #  \n",
        "\n",
        "    # ========= Step 1: build transformations for the dataset ===========\n",
        "    # You need to construct build a data transformation that does three preprocessings in order:\n",
        "    # I.   Resize the image to input_size using transforms.Resize\n",
        "    # II.  Convert the image to PyTorch tensor using transforms.ToTensor\n",
        "    # III. Normalize the images with the provided mean and std parameters using transforms.Normalize. These parameters are accumulated from a large number of training samples.\n",
        "    # You can use transforms.Compose to combine the above three transformations. Store the combined transforms in variable 'composed_transform'.\n",
        "    composed_transform = transforms.Compose([transforms.Resize(input_size), transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
        "\n",
        "    \n",
        "    # ============== END OF CODE ================= # \n",
        "    #++++++++++++++++++++++++++++++++++++++++++++++#\n",
        "    #++++++++++++++++++++++++++++++++++++++++++++++#\n",
        "\n",
        "    # We write the remaining part of the dataloader for you.  \n",
        "    # You are encouraged to go through this.\n",
        "\n",
        "    # ========= Step 2: We build dataloaders for the downloaded data ===========\n",
        "    # I.   We use torch.datasets.ImageFolder with the provided data_dir and the data transfomations you created in step 1 to contruct pytorch datasets for train/val/test \n",
        "    # II.  Then we use torch.utils.data.DataLoader to build dataloaders with the constructed pytorch datasets, you need to enable shuffling for training set. Set num_workers=2 to speed up dataloading.\n",
        "    # III. Finally, we put the dataloaders into a dictionary\n",
        "\n",
        "    # Create train/val/test datasets\n",
        "    data_transforms = {\n",
        "        'train': composed_transform,\n",
        "        'val': composed_transform,\n",
        "        'test': composed_transform\n",
        "    }\n",
        "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in data_transforms.keys()}\n",
        "\n",
        "    # Create training train/val/test dataloaders\n",
        "    # Never shuffle the val and test datasets\n",
        "    dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False if x != 'train' else shuffle, num_workers=2) for x in data_transforms.keys()}\n",
        "    \n",
        "\n",
        "\n",
        "    return dataloaders_dict"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ85VyUwKeju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491cc873-d2e3-4c9a-ac53-e76483b5a8bb"
      },
      "source": [
        "batch_size = 16\n",
        "input_size = 128\n",
        "dataloaders_dict = get_dataloaders(input_size, batch_size)\n",
        "\n",
        "# Confirm your train/val/test sets contain 90,000/10,000/10,000 samples\n",
        "print('# of training samples {}'.format(len(dataloaders_dict['train'].dataset))) \n",
        "print('# of validation samples {}'.format(len(dataloaders_dict['val'].dataset)))  \n",
        "print('# of test samples {}'.format(len(dataloaders_dict['test'].dataset))) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of training samples 200\n",
            "# of validation samples 400\n",
            "# of test samples 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6yXydgmnKjg"
      },
      "source": [
        "# Helper function for counting number of trainable parameters.\n",
        "def count_params(model):\n",
        "    '''\n",
        "    Counts the number of trainable parameters in PyTorch.\n",
        "\n",
        "    Args:\n",
        "        model: PyTorch model.\n",
        "\n",
        "    Returns:\n",
        "        num_params: int, number of trainable parameters.\n",
        "    '''\n",
        "\n",
        "    num_params = sum([item.numel() for item in model.parameters() if item.requires_grad])\n",
        "\n",
        "    return num_params"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVzbyGMQxW8c"
      },
      "source": [
        "# Network configurations for all layers before the final fully-connected layers. \n",
        "# \"M\" corresponds to maxpooling layer, integers correspond to number of output channels of a convolutional layer.\n",
        "cfgs = {\n",
        "    'MiniVGG': [64, 'M', 128, 'M', 128, 128, 'M'],\n",
        "    'MiniVGG-BN': [64, 'M', 128, 'M', 128, 128, 'M']\n",
        "}\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "\n",
        "    '''\n",
        "    Return a nn.Sequential object containing all layers to get the features using the CNN.\n",
        "    (That is, before the Average pooling layer in the two pictures above). \n",
        "\n",
        "    Args:\n",
        "      cfg: list\n",
        "      batch_norm: bool, default: False. If set to True, a BatchNorm layer should be added after each convolutional layer.\n",
        "\n",
        "    Return:\n",
        "      features: torch.nn.Sequential. Containers for all feature extraction layers. For use of torch.nn.Sequential, please refer to PyTorch documents.\n",
        "    '''\n",
        "    #++++++++++++++++++++++++++++++++++++++++++++++#\n",
        "    #++++++++++++++++++++++++++++++++++++++++++++++#\n",
        "    # ============== YOUR CODE HERE ============== # \n",
        "    layers = []\n",
        "    temp = 3\n",
        "    for layer in cfg:\n",
        "      if layer == 'M':\n",
        "        layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding = 0, dilation = 1, ceil_mode = False)]\n",
        "      else:\n",
        "        convolved = nn.Conv2d(temp, layer, kernel_size=(3, 3), stride = (1, 1), padding=(1, 1))\n",
        "        temp = layer\n",
        "        if batch_norm:\n",
        "          layers+=([convolved, nn.BatchNorm2d(temp), nn.ReLU(inplace=True)])\n",
        "        else:\n",
        "          layers+=([convolved, nn.ReLU(inplace=True)])\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "    # ============== END OF CODE ================= # \n",
        "    #++++++++++++++++++++++++++++++++++++++++++++++#\n",
        "    #++++++++++++++++++++++++++++++++++++++++++++++#\n",
        "\n",
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self, features, num_classes=100, init_weights=True):\n",
        "        super(VGG, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((5, 5))\n",
        "\n",
        "         \n",
        "        #++++++++++++++++++++++++++++++++++++++++++++++#\n",
        "        #++++++++++++++++++++++++++++++++++++++++++++++#\n",
        "        # ============== YOUR CODE HERE ============== #\n",
        "        # Construct the final FC layers using nn.Sequential.\n",
        "        # NOTE: The avgpool layer has already been defined by us above.\n",
        "         \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features = 3200,out_features = 512,bias= True),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(p=0.3, inplace = False),\n",
        "            nn.Linear(in_features = 512,out_features = 256,bias= True),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(p=0.3, inplace = False),\n",
        "            nn.Linear(in_features = 256,out_features = 100,bias= True),\n",
        "        )\n",
        "        \n",
        "        # ============== END OF CODE ================= # \n",
        "        #++++++++++++++++++++++++++++++++++++++++++++++#\n",
        "        #++++++++++++++++++++++++++++++++++++++++++++++#\n",
        "\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IBbv7mW0gFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "367afdb6-fcf6-448b-e9bb-5935dd35da19"
      },
      "source": [
        "features = make_layers(cfgs['MiniVGG'], batch_norm=False)\n",
        "vgg = VGG(features)\n",
        "\n",
        "features = make_layers(cfgs['MiniVGG-BN'], batch_norm=True)\n",
        "vgg_bn = VGG(features)\n",
        "\n",
        "# Print the network architectrue. Please compare the printed architecture with the one given in the instruction above. \n",
        "# Make sure your network has the same architecture as the one we give above.\n",
        "print(vgg)\n",
        "print('Number of trainable parameters {}'.format(count_params(vgg)))\n",
        "\n",
        "print(vgg_bn)\n",
        "print('Number of trainable parameters {}'.format(count_params(vgg_bn)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(5, 5))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=3200, out_features=512, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.3, inplace=False)\n",
            "    (6): Linear(in_features=256, out_features=100, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of trainable parameters 2166756\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(5, 5))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=3200, out_features=512, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.3, inplace=False)\n",
            "    (6): Linear(in_features=256, out_features=100, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of trainable parameters 2167652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSAKSY96ZLZC"
      },
      "source": [
        "def make_optimizer(model):\r\n",
        "  '''Args:model: NN to trainReturns:optimizer: pytorch optmizer for updating the given model parameters.'''\r\n",
        "  #++++++++++++++++++++++++++++++++++++++++++++++#\r\n",
        "  #++++++++++++++++++++++++++++++++++++++++++++++#\r\n",
        "  # ============== YOUR CODE HERE ============== #\r\n",
        "  # Create a SGD optimizer with a learning rate 1e-2, momentum = 0.9\r\n",
        "  # HINT:\r\n",
        "  # We have imported torch.optim as optim for you\r\n",
        "  # Checkout optim.SGD() and initialize with appropriate parameters\r\n",
        "  params_to_update=model.parameters()\r\n",
        "  #optimizer = optim.Adam(params_to_update, lr=1e-3)\r\n",
        "  optimizer=optim.SGD(params_to_update, lr=1e-1, momentum=0.9)\r\n",
        "  # ============== END OF CODE ================= #\r\n",
        "  #++++++++++++++++++++++++++++++++++++++++++++++#\r\n",
        "  #++++++++++++++++++++++++++++++++++++++++++++++#\r\n",
        "  return optimizer\r\n",
        "\r\n",
        "def get_loss():\r\n",
        "  criterion=nn.CrossEntropyLoss()\r\n",
        "  return criterion"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYGmDsrzY4Ir"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, save_dir = None, num_epochs=25, model_name='MiniVGG'):\n",
        "    '''\n",
        "    Args:\n",
        "        model: The NN to train\n",
        "        dataloaders: A dictionary containing at least the keys \n",
        "                    'train','val' that maps to Pytorch data loaders for the dataset\n",
        "        criterion: The Loss function\n",
        "        optimizer: Pytroch optimizer. The algorithm to update weights \n",
        "        num_epochs: How many epochs to train for\n",
        "        save_dir: Where to save the best model weights that are found. Using None will not write anything to disk.\n",
        "\n",
        "    Returns:\n",
        "        model: The trained NN\n",
        "        tr_acc_history: list, training accuracy history. Recording freq: one epoch.\n",
        "        val_acc_history: list, validation accuracy history. Recording freq: one epoch.\n",
        "    '''\n",
        "\n",
        "    val_acc_history = []\n",
        "    tr_acc_history = []\n",
        "    \n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            # loss and number of correct prediction for the current batch\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            # TQDM has nice progress bars\n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                #++++++++++++++++++++++++++++++++++++++++++++++#\n",
        "                #++++++++++++++++++++++++++++++++++++++++++++++# \n",
        "                # ============== YOUR CODE HERE ============== #\n",
        "#def train_model(model, dataloaders, criterion, optimizer, save_dir = None, num_epochs=25, model_name='MiniVGG'):\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                with torch.set_grad_enabled(phase=='train'):\n",
        "                  # Get model outputs and calculate loss\n",
        "                  outputs=model(inputs)\n",
        "                  loss=criterion(outputs, labels)\n",
        "                  # torch.max outputs the maximum value, and its index\n",
        "                  # Since the input is batched, we take the max along axis 1\n",
        "                  # (the meaningful outputs)\n",
        "                  _, preds=torch.max(outputs,1)\n",
        "                  # backprop + optimize only if in training phase\n",
        "                  if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                # Please read all the inputs carefully!\n",
        "                # For \"train\" phase: \n",
        "                # (i)   Compute the outputs using model\n",
        "                #       Also, use outputs to calculate predicted class by model,\n",
        "                #       Store the predicted class in variable 'preds'\n",
        "                #       (Think argmax of outputs across a dimension)\n",
        "                #       torch.max() might help!\n",
        "                # (ii)  Calculate the loss using criterion. Store it as 'loss' \n",
        "                # (iii) Update the model parameters\n",
        "\n",
        "                # Don't forget to zero the gradients for each iteration!\n",
        "                \n",
        "                # For \"val\" phase, same as train but without backprop \n",
        "                # Compute the outputs (Same as \"train\", calculate 'preds' also), \n",
        "                # Calculate the loss, store it as 'loss'\n",
        "\n",
        "\n",
        "                # ============== END OF CODE ================= # \n",
        "                #++++++++++++++++++++++++++++++++++++++++++++++#\n",
        "                #++++++++++++++++++++++++++++++++++++++++++++++# \n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "                # save the best model weights\n",
        "                # ================================ IMPORTANT ===============================================\n",
        "                # Lossing connection to colab will lead to loss of trained weights.\n",
        "                # You can download the trained weights to your local machine. \n",
        "                # Later, you can load these weights directly without needing to train the neural networks again.\n",
        "                # ==========================================================================================\n",
        "                if save_dir:\n",
        "                    torch.save(best_model_wts, os.path.join(save_dir, model_name + '.pth'))\n",
        "\n",
        "            # record the train/val accuracies\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "            else:\n",
        "                tr_acc_history.append(epoch_acc)\n",
        "                \n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    return model, tr_acc_history, val_acc_history"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqEGeODmZJtM"
      },
      "source": [
        "# Number of classes in the dataset\n",
        "# Miniplaces has 100\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training \n",
        "batch_size = 128\n",
        "\n",
        "# Shuffle the input data?\n",
        "shuffle_datasets = True\n",
        "\n",
        "# Number of epochs to train for\n",
        "# During debugging, you can set this parameter to 1\n",
        "# num_epochs = 1\n",
        "# Training for 20 epochs. This will take about half an hour.\n",
        "num_epochs = 20\n",
        "\n",
        "### IO\n",
        "# Directory to save weights to\n",
        "save_dir = \"weights\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# get dataloders and criterion function\n",
        "input_size = 64 # do not change this\n",
        "dataloaders = get_dataloaders(input_size, batch_size, shuffle_datasets)\n",
        "criterion = get_loss()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCnO1JytyDBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de770f6-ed93-4b6d-8edb-7009b484f47b"
      },
      "source": [
        "# Initialize MiniVGG-BN\n",
        "features = make_layers(cfgs['MiniVGG-BN'], batch_norm=True)\n",
        "model = VGG(features).to(device)\n",
        "optimizer = make_optimizer(model)\n",
        "\n",
        "# Train the model!\n",
        "vgg_BN, tr_his_BN, val_his_BN = train_model(model=model, dataloaders=dataloaders, criterion=criterion, optimizer=optimizer,\n",
        "           save_dir=save_dir, num_epochs=num_epochs, model_name='MiniVGG-BN')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.08it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 4.5366 Acc: 0.2250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.59it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 4.3487 Acc: 0.5050\n",
            "Epoch 1/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.00it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 2.7280 Acc: 0.5150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.60it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 1.2324 Acc: 0.5000\n",
            "Epoch 2/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.05it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 15.9712 Acc: 0.5200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.59it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 3.5220 Acc: 0.5000\n",
            "Epoch 3/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.09it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 3.8832 Acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.58it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 102.8992 Acc: 0.5000\n",
            "Epoch 4/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.08it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 4.2404 Acc: 0.5050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.54it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 16.0162 Acc: 0.5000\n",
            "Epoch 5/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.00it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 2.3111 Acc: 0.5050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.63it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 21.1415 Acc: 0.5000\n",
            "Epoch 6/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.08it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 7.6470 Acc: 0.4600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.63it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 1.9321 Acc: 0.5000\n",
            "Epoch 7/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.04it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 2.1590 Acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.58it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 2.5450 Acc: 0.5000\n",
            "Epoch 8/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.06it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 1.9358 Acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.58it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 1.8145 Acc: 0.5000\n",
            "Epoch 9/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.01it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 1.7367 Acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.61it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 1.2262 Acc: 0.5000\n",
            "Epoch 10/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.03it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 1.2642 Acc: 0.4950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.59it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 1.0338 Acc: 0.4875\n",
            "Epoch 11/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.99it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 1.0193 Acc: 0.5350\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.55it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.8293 Acc: 0.4950\n",
            "Epoch 12/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.08it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.9197 Acc: 0.4600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.62it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.7924 Acc: 0.5000\n",
            "Epoch 13/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.07it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.8319 Acc: 0.5150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.53it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.7765 Acc: 0.4975\n",
            "Epoch 14/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.03it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.8492 Acc: 0.4700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.56it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.7446 Acc: 0.5150\n",
            "Epoch 15/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.7539 Acc: 0.5500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.58it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.7642 Acc: 0.5100\n",
            "Epoch 16/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.01it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.7236 Acc: 0.5400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.54it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.7717 Acc: 0.5200\n",
            "Epoch 17/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.02it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.7554 Acc: 0.5400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.53it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.7801 Acc: 0.4875\n",
            "Epoch 18/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  3.00it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.7149 Acc: 0.5500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.53it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.7557 Acc: 0.5125\n",
            "Epoch 19/19\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.99it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.7012 Acc: 0.5750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.7484 Acc: 0.5075\n",
            "Best val Acc: 0.520000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFW-kIwfblUe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "4fbdfd51-6679-456d-ed93-a24c0f8b8ba8"
      },
      "source": [
        "# visualize the training / validation accuracies\n",
        "\n",
        "x = np.arange(num_epochs)\n",
        "\n",
        "\n",
        "# train/val accuracies for MiniVGG-BN\n",
        "plt.plot(x, tr_his_BN)\n",
        "plt.plot(x, val_his_BN)\n",
        "plt.legend(['Training top1 accuracy', 'Validation top1 accuracy'])\n",
        "plt.xticks(x)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Top1 Accuracy')\n",
        "plt.title('MiniVGG-BN')\n",
        "plt.show()\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZdFjScPblUg"
      },
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    '''\n",
        "    Computes the accuracy over the k top predictions for the specified values of k.\n",
        "    \n",
        "    Args:\n",
        "        output: pytorch tensor, (batch_size x num_classes). Outputs of the network for one batch.\n",
        "        target: pytorch tensor, (batch_size,). True labels for one batch.\n",
        "    \n",
        "    Returns:\n",
        "        res: list. Accuracies corresponding to topk[0], topk[1], ...\n",
        "    '''\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "def test(model, dataloader):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    top1_acc = []\n",
        "    top5_acc = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            res = accuracy(outputs, labels, topk=(1, 5))\n",
        "\n",
        "            top1_acc.append(res[0] * len(outputs))\n",
        "            top5_acc.append(res[1] * len(outputs))\n",
        "\n",
        "    print('Top-1 accuracy {}%, Top-5 accuracy {}%'.format(sum(top1_acc).item()/10000, sum(top5_acc).item()/10000))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4V_qjYFCLHV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a3c90d4-afbe-4d23-ad47-626d1362113d"
      },
      "source": [
        "##### To pass the test, both networks should have Top-5 accuracy above 55% #####\n",
        "# uncomment these two lines to load pretrained weights\n",
        "vgg_BN.load_state_dict(torch.load('./weights/MiniVGG-BN.pth'))\n",
        "print(vgg_BN.eval()) \n",
        "test(vgg_BN, dataloaders['test'])\n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(5, 5))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=3200, out_features=512, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.3, inplace=False)\n",
            "    (6): Linear(in_features=256, out_features=100, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-ff56e1dc9e72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvgg_BN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./weights/MiniVGG-BN.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_BN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_BN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-855137e06711>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 64, 67] at entry 0 and [3, 64, 64] at entry 2\n"
          ]
        }
      ]
    }
  ]
}